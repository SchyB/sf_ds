{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df = pd.read_csv('data/melb_data_fe.csv')\n",
    "melb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(melb_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df['Date'] = pd.to_datetime(melb_df['Date']) \n",
    "display(melb_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quart_sold = melb_df['Date'].dt.quarter\n",
    "print(quart_sold.value_counts())\n",
    "#print(quarters.value_counts().iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_exclude = ['Date', 'Rooms', 'Bedroom', 'Bathroom', 'Car'] \n",
    "max_unique_count = 150 \n",
    "for col in melb_df.columns: \n",
    "    if melb_df[col].nunique() < max_unique_count and col not in cols_to_exclude: \n",
    "        melb_df[col] = melb_df[col].astype('category') \n",
    "display(melb_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by — имя или список имён столбцов, по значениям которых производится сортировка.\n",
    "axis — ось, по которой производится сортировка (0 — строки, 1 — столбцы). По умолчанию сортировка производится по строкам.\n",
    "ascending — сортировка по возрастанию (от меньшего к большему). По умолчанию параметр выставлен на True, для сортировки по убыванию (от большего к меньшему) необходимо выставить его на False.\n",
    "ignore_index — создаются ли новые индексы в таблице. По умолчанию выставлен на False и сохраняет индексы изначальной таблицы.\n",
    "inplace — производится ли замена исходной таблицы на отсортированную. По умолчанию параметр выставлен на False, то есть замены не производится. Чтобы переопределить исходную таблицу на отсортированную, необходимо выставить этот параметр на True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.sort_values(by='Price').head(10) #Отсортируем таблицу по возрастанию цены объектов недвижимости (Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.sort_values(by='Date', ascending=False) #отсортируем таблицу по убыванию даты продажи объекта (Date). Для этого выставим параметр ascending на False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.sort_values(by=['Distance', 'Price']).loc[::10, ['Distance', 'Price']] #отсортируем таблицу сначала по возрастанию расстояния от центра города (Distance), а затем — по возрастанию цены объекта (Price). выделим каждую десятую строку из столбцов Distance и Price результирующей таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = melb_df['AreaRatio'] < -0.8\n",
    "mask2 = melb_df['Type'] == 'townhouse'\n",
    "mask3 = melb_df['SellerG'] == 'McGrath'\n",
    "melb_df[mask1 & mask2 & mask3].sort_values(\n",
    "    by=['Date', 'AreaRatio'],\n",
    "    ascending=[True, False],\n",
    "    ignore_index=True\n",
    ").loc[:, ['Date', 'AreaRatio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.sort_values(by='AreaRatio', ascending=False, ignore_index=True).iloc[1558]\n",
    "#int(melb_df.sort_values(\n",
    "    #by='AreaRatio', \n",
    "    #ignore_index=True,\n",
    "    #ascending=False\n",
    "#).loc[1558, 'BuildingArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = melb_df[(melb_df['Rooms'] > 2) & (melb_df['Type'] == 'townhouse')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.sort_values(by=['Rooms', 'MeanRoomsSquare'], ascending=[True, False], ignore_index=True).iloc[18]\n",
    "#mask1 = melb_df['Type'] == 'townhouse'\n",
    "#mask2 = melb_df['Rooms'] > 2\n",
    "#int(melb_df[mask1&mask2].sort_values(\n",
    "    #by=['Rooms', 'MeanRoomsSquare'],\n",
    "    #ascending=[True, False],\n",
    "    #ignore_index=True\n",
    "#).loc[18, 'Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by — имя или список имён столбцов, по которым производится группировка.\n",
    "axis — ось, по которой производится группировка (0 — строки, 1 — столбцы). По умолчанию группировка производится по строкам.\n",
    "as_index — добавляется ли дополнительный индекс к таблице. По умолчанию установлен на True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.groupby(by='Type').mean(numeric_only=True) #Если мы хотим видеть тип объекта в качестве отдельного столбца таблицы, мы можем выставить параметр as_index на False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.groupby('Type')['Price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.groupby('Regionname')['Distance'].min().sort_values(ascending=False) # найдём минимальное значение расстояния от центра города до объекта в зависимости от его региона. Результат отсортируем по убыванию расстояния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.groupby('MonthSale')['Price'].agg(\n",
    "    ['count', 'mean', 'max']\n",
    ").sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.groupby('MonthSale')['Price'].agg('describe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.groupby('Regionname')['SellerG'].agg(\n",
    "    \t\t['nunique', set]\n",
    ") #подсчёт числа уникальных значений, set - получить множество из агентств недвижимости, которые работают в каждом из регионов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.groupby('Rooms')['Price'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.groupby('Regionname')['Lattitude'].std().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_price = melb_df[(melb_df['Date'] >= '2017-05-01') & (melb_df['Date'] <= '2017-09-01')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_price.groupby('SellerG')['Price'].sum().sort_values()\n",
    "#date1 = pd.to_datetime('2017-05-01')\n",
    "#date2 = pd.to_datetime('2017-09-01')\n",
    "#mask = (date1 <= melb_df['Date']) & (melb_df['Date']<= date2)\n",
    "#melb_df[mask].groupby('SellerG')['Price'].sum().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.groupby('Rooms')[['Price', 'BuildingArea']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.groupby(['Rooms', 'Type'])['Price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.groupby(['Rooms', 'Type'])['Price'].mean().unstack() #финальный результат представлен в виде сводной таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "values — имя столбца, по которому необходимо получить сводные данные, применяя агрегирующую функцию;\n",
    "index — имя столбца, значения которого станут строками сводной таблицы;\n",
    "columns — имя столбца, значения которого станут столбцами сводной таблицы;\n",
    "aggfunc — имя или список имён агрегирующих функций (по умолчанию — подсчёт среднего, 'mean');\n",
    "fill_value — значение, которым необходимо заполнить пропуски (по умолчанию пропуски не заполняются)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.pivot_table(\n",
    "    values='Price',\n",
    "    index='Rooms',\n",
    "    columns='Type',    fill_value=0\n",
    ").round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.pivot_table(\n",
    "    values='Price',\n",
    "    index='Regionname',\n",
    "    columns='Weekend',\n",
    "    aggfunc='count'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.pivot_table(\n",
    "    values='Landsize',\n",
    "    index='Regionname',\n",
    "    columns='Type',\n",
    "    aggfunc=['median', 'mean'],\n",
    "    fill_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.pivot_table(\n",
    "    values='Price',\n",
    "    index=['Method','Type'],\n",
    "    columns='Regionname',\n",
    "    aggfunc='median',\n",
    "    fill_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = melb_df.pivot_table(\n",
    "    values='Landsize',\n",
    "    index='Regionname',\n",
    "    columns='Type',\n",
    "    aggfunc=['median', 'mean'],\n",
    "    fill_value=0\n",
    ")\n",
    "pivot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pivot['mean']['unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pivot['mean']['house'] < pivot['median']['house']\n",
    "filtered_pivot = pivot[mask]\n",
    "display(filtered_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(filtered_pivot.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.pivot_table(\n",
    "    values='BuildingArea',\n",
    "    index='Rooms',\n",
    "    columns='Type',\n",
    "    aggfunc='median',\n",
    "    fill_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melb_df.pivot_table(\n",
    "    values='Price',\n",
    "    index='SellerG',\n",
    "    columns='Type',\n",
    "    aggfunc='median',\n",
    "    fill_value=0\n",
    ")\n",
    "#max_unit_price = pivot['unit'].max()\n",
    "#print(pivot[pivot['unit'] == max_unit_price].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('data/movies.csv')\n",
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat1_df = pd.read_csv('data/ratings1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df = pd.read_csv('data/dates.csv')\n",
    "dates_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.read_csv('data/dates.csv')\n",
    "movies = pd.read_csv('data/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat1_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df['date'] = pd.to_datetime(dates_df['date'])\n",
    "prem_year = dates_df['date'].dt.year\n",
    "print(prem_year.mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objs — список объектов DataFrame ([df1, df2,…]), которые должны быть сконкатенированы;\n",
    "axis — ось определяет направление конкатенации: 0 — конкатенация по строкам (по умолчанию), 1 — конкатенация по столбцам;\n",
    "join — либо inner (пересечение), либо outer (объединение); рассмотрим этот момент немного позже;\n",
    "ignore_index — по умолчанию установлено значение False, которое позволяет значениям индекса оставаться такими, какими они были в исходных данных. Если установлено значение True, параметр будет игнорировать исходные значения и повторно назначать значения индекса в последовательном порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1 = pd.read_csv('data/ratings1.csv')\n",
    "ratings2 = pd.read_csv('data/ratings2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.concat(\n",
    "    [ratings1, ratings2],\n",
    "    ignore_index=True\n",
    ")\n",
    "display(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Число строк в таблице ratings: ', ratings.shape[0])\n",
    "print('Число строк в таблице dates: ', dates.shape[0])\n",
    "print(ratings.shape[0] == dates.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ratings1.tail(1))\n",
    "display(ratings2.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число строк в таблице ratings:  100836\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings.drop_duplicates(ignore_index=True)\n",
    "print('Число строк в таблице ratings: ', ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dates = pd.concat([ratings, dates], axis=1)\n",
    "display(ratings_dates.tail(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_user_files(path):\n",
    "    file_lst = []\n",
    "    for file in os.listdir(path):\n",
    "        file_lst.append(os.path.join(path, file))\n",
    "    file_lst.sort()\n",
    "    df_lst = []\n",
    "    for file_name in file_lst:\n",
    "        file_df = pd.read_csv(file_name)\n",
    "        df_lst.append(file_df)\n",
    "    total = pd.concat(df_lst)\n",
    "    total = total.drop_duplicates(ignore_index=True)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_user_files(path):\n",
    "    data = pd.DataFrame()\n",
    "    file_names = os.listdir(path)\n",
    "    file_names.sort()\n",
    "    for file in file_names:\n",
    "        tmp_data = pd.read_csv(path + '/' + file)\n",
    "        data = pd.concat([data, tmp_data], axis=0, ignore_index=True)\n",
    "    data = data.drop_duplicates()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JOIN\n",
    "other — таблица, которую мы присоединяем. При объединении она является «правой», а исходная таблица, от имени которой вызывается метод, является «левой».\n",
    "how — параметр типа объединения. Он может принимать значения 'inner', 'left' (left outer), 'right' (right outer), и 'outer' (full outer). По умолчанию параметр установлен на 'left'.\n",
    "on — параметр, который определяет, по какому столбцу в «левой» таблице происходит объединение по индексам из «правой».\n",
    "lsuffix и rsuffix — дополнения (суффиксы) к названиям одноимённых столбцов в «левой» и «правой» таблицах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_false = ratings_dates.join(\n",
    "    movies,\n",
    "    rsuffix='_right',\n",
    "    how='left'\n",
    ")\n",
    "display(joined_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = ratings_dates.join(\n",
    "    movies.set_index('movieId'),\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")\n",
    "display(joined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGE\n",
    "right — присоединяемая таблица. По умолчанию она является «правой».\n",
    "how — параметр типа объединения. По умолчанию принимает значение 'inner'.\n",
    "on — параметр, который определяет, по какому столбцу происходит объединение. Определяется автоматически, но рекомендуется указывать вручную.\n",
    "left_on — если названия столбцов в «левой» и «правой» таблицах не совпадают, то данный параметр отвечает за наименования ключевого столбца исходной таблицы.\n",
    "right_on — аналогично предыдущему, параметр отвечает за наименование ключевого столбца присоединяемой таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = ratings_dates.merge(\n",
    "    movies,\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")\n",
    "display(merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число строк в таблице ratings_dates:  100836\n",
      "Число строк в таблице merged:  100836\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('Число строк в таблице ratings_dates: ', ratings_dates.shape[0])\n",
    "print('Число строк в таблице merged: ', merged.shape[0])\n",
    "print(ratings_dates.shape[0] == merged.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_ratings = ratings1.merge(ratings2, how='outer')\n",
    "print('Число строк в таблице merge_ratings: ', merge_ratings.shape[0])\n",
    "display(merge_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = items_df.merge(purchase_df, on='item_id', how='inner')\n",
    "income = (merged['stock_count'] * merged['price']).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
